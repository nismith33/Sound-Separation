{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4464680c",
   "metadata": {},
   "source": [
    "In this notebook we will define/test a function for separating the \"foreground\" and \"background\" of a song (as defined in the included paper).\n",
    "\n",
    "[Examples of algorithm results linked by authors in paper](https://interactiveaudiolab.github.io/demos/2dft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c530075e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile\n",
    "from scipy.fft import fft2, ifft2\n",
    "from scipy.signal import stft, istft\n",
    "import numpy as np\n",
    "\"\"\"\n",
    "song_cut returns the \"foreground\" and \"background\" tracks. \n",
    "sound_filename, the song to be processed, should be a .wav file. \n",
    "radius is the radius of the neighborhood we use to define a peak. Larger radius values (close to 100) may cause background \n",
    "to leak into the foreground track, smaller radius values (close to 15) may cause the opposite.\n",
    "\n",
    "In addition, this program assumes mono-track inputs with very little metadata attached. Such preprocessing can be performed \n",
    "in the free program Audacity.\n",
    "\"\"\"\n",
    "def song_cut(sound_filename,radius):\n",
    "    samplerate, sound_data = wavfile.read(sound_filename)\n",
    "    \n",
    "    #the short time fourier transform turns our 1-dimensional sound information into a two dimension fequency/time plot.\n",
    "    #nperseg and noverlap must be preserved so we can invert this short time transform later.\n",
    "    nperseg_choice = 8192\n",
    "    noverlap_choice = nperseg_choice/2\n",
    "    sample_frequencies, segment_times, sound_stft = stft(sound_data, nperseg = nperseg_choice, noverlap = noverlap_choice)\n",
    "\n",
    "    #the sound-rate spectrogram is generated by taking the 2D fourier transform of the magnitude of sound_stft\n",
    "    spectrogram = fft2(np.absolute(sound_stft))\n",
    "\n",
    "    #Now we want to find any peaks in the magnitude of spectrogram along the rate axis.\n",
    "    spec_mag = np.absolute(spectrogram)\n",
    "    threshold = np.std(spec_mag)\n",
    "    dims = spec_mag.shape\n",
    "\n",
    "    #iterate through all points in spec_mag, finding and marking peaks in background_mask\n",
    "    background_mask = np.zeros(dims)\n",
    "    for i in range(dims[0]):\n",
    "        for j in range(dims[1]):\n",
    "            #\"\"\"\n",
    "            #if we get too close to the edges we will make the neighborhoods slightly smaller\n",
    "            if j<radius and dims[1]-j < radius:\n",
    "                neighborhood = spec_mag[i][0:dims[1]]\n",
    "            elif j<radius:\n",
    "                neighborhood = spec_mag[i][0:j+radius+1]\n",
    "            elif dims[1]-j < radius:\n",
    "                neighborhood = spec_mag[i][j-radius:dims[1]]\n",
    "            else:\n",
    "                neighborhood = spec_mag[i][j-radius: j+radius+1]\n",
    "            nbhd_range = np.amax(neighborhood)-np.amin(neighborhood)\n",
    "            #if nbhd_range is less than threshold we do not care\n",
    "            if nbhd_range > threshold and spec_mag[i][j]== np.amax(neighborhood):\n",
    "                background_mask[i][j] = 1\n",
    "    #Here we separate the foreground and background portions of the signal\n",
    "    foreground_mask = np.ones(dims)- background_mask\n",
    "    foreground_spetrogram_magnitude = ifft2(np.multiply(foreground_mask,spectrogram))\n",
    "    background_spetrogram_magnitude = ifft2(np.multiply(background_mask,spectrogram))\n",
    "    time_background_mask = np.greater(background_spetrogram_magnitude, foreground_spetrogram_magnitude)\n",
    "    time_foreground_mask = np.ones(time_background_mask.shape) - time_background_mask\n",
    "    foreground_track = istft(np.multiply(time_foreground_mask,sound_stft), nperseg = nperseg_choice, noverlap = noverlap_choice) \n",
    "    background_track = istft(np.multiply(time_background_mask,sound_stft), nperseg = nperseg_choice, noverlap = noverlap_choice)\n",
    "    #now turned back into 1d signals, we save as WAV files\n",
    "    foreground_filename = 'foreground_'+sound_filename\n",
    "    background_filename = 'background_'+sound_filename\n",
    "    #want output file to have the same data type as input audio\n",
    "    wavfile.write(foreground_filename, samplerate, foreground_track[1].astype('int16'))\n",
    "    wavfile.write(background_filename, samplerate, background_track[1].astype('int16'))\n",
    "    print('Separation Complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ebe13f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separation Complete.\n",
      "Separation Complete.\n",
      "Separation Complete.\n",
      "Separation Complete.\n",
      "Separation Complete.\n",
      "Separation Complete.\n"
     ]
    }
   ],
   "source": [
    "#These songs were recordings of other songs on my phone. Not sure how much (if at all) the ambient air noise added\n",
    "#affects the results\n",
    "song_cut('blood.wav',30)\n",
    "song_cut('burningForYou.wav',30)\n",
    "song_cut('iCouldBeYours.wav',30)\n",
    "song_cut('magentaMountain.wav',30)\n",
    "\n",
    "#These were taken from the MUSDB18 dataset:\n",
    "# https://sigsep.github.io/datasets/musdb.html#musdb18-compressed-stems\n",
    "#since I wanted .WAV files that weren't recordings from my phone.\n",
    "song_cut('mixture.wav',30)\n",
    "song_cut('mixture2.wav',30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
